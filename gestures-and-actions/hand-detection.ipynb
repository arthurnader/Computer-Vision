{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11fe46e3-c74f-47e0-ac64-f62898e95ccf",
   "metadata": {},
   "source": [
    "# Hand detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4e359-0ec7-4be1-beb3-4aabaacf2c42",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34ca914b-4254-47d4-be25-34cfce042d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.10.0'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c308c42-d7ad-4e95-99f6-e23224f6160d",
   "metadata": {},
   "source": [
    "## Extracting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c591b654-4531-4e05-8d12-188402c5a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_path = \"pose.zip\"\n",
    "zip_object = zipfile.ZipFile(file = pose_path, mode = \"r\") \n",
    "zip_object.extractall(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a730833a-0ff7-411e-b964-fcef031bf45d",
   "metadata": {},
   "source": [
    "## Defining the path to the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d44806d-86c7-4b86-8484-7b2e3916f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_file = \"pose/hand/pose_deploy.prototxt\"\n",
    "weights_file = \"pose/hand/pose_iter_102000.caffemodel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f01b4-595c-471f-9779-47620552ccaa",
   "metadata": {},
   "source": [
    "## Defining the number of points and the pairs of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "003b8eff-837b-4a23-8fc4-9a785343272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_points = 22\n",
    "pairs = [[0, 1], [1, 2], [2, 3], [3, 4], [0, 5], [5, 6], [6, 7], [7, 8],\n",
    "              [0, 9], [9, 10], [10, 11], [11, 12], [0, 13], [13, 14], [14, 15],\n",
    "              [15, 16], [0, 17], [17, 18], [18, 19], [19, 20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5a4d1c-6647-4989-adac-f3cd0e09b9c4",
   "metadata": {},
   "source": [
    "## Loading an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bfcd465-96ab-4a78-bab3-266996cbdc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"hand.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b3d4f84-0908-41ef-ba7f-cc5220d55fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(612, 612, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a15868d7-5809-4d99-9810-8f31997d7bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow('hand', img)\n",
    "cv2.waitKey(0)  # Wait for a key press to close the window\n",
    "cv2.destroyAllWindows()  # Close the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70d463be-5954-4c31-b0aa-e3229fb302db",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = np.copy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c7d8a1-9ce5-46d3-a03f-61a4fa5e8b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width = img.shape[1]\n",
    "heigth = img.shape[0]\n",
    "proportion = width / heigth\n",
    "proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cd0f2fa-6e8f-4490-8b54-c340dc6e143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointA_color, pointB_color, line_color = (25, 24, 228), (25, 24, 228), (12, 192, 92)\n",
    "txtpoint_color = (25, 16, 245)\n",
    "\n",
    "font_size, line_size, circle_size, thickness_ = 5, 1, 4, 2\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59c38c0-d798-4e0c-ac6a-273ddcaa58c5",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab9675d5-c73f-443a-bb25-64c19f4ed122",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.dnn.readNetFromCaffe(proto_file, weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6331b3-0a89-43ab-9517-839d64978ad3",
   "metadata": {},
   "source": [
    "## Changing the size of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "147c6690-e0f9-450f-979c-e07fd2763db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_height = 256\n",
    "new_width = int((proportion*new_height)*8//8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6dd8cde-cb75-40c7-b28e-6e1b685b5cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_height, new_width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e00b05-aeee-4edb-94ca-f540737a80b4",
   "metadata": {},
   "source": [
    "## Converting the imate from cv2 to blob Caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3333db65-dfe2-4e46-8bbe-de45889fcc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_entry = cv2.dnn.blobFromImage(img, 1.0 / 255,\n",
    "                                     (new_width, new_height),\n",
    "                                     (0, 0, 0), swapRB=False, crop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba9f66-d514-450b-925e-f93d4a0348ca",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d104f95-d783-40d0-8f17-bebd2c75a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.setInput(blob_entry)\n",
    "output = model.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f5c2339-a5b9-413a-b833-05a4b08d7f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 22, 32, 32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b1ed1e-266d-4d6d-92db-222bcb33ea93",
   "metadata": {},
   "source": [
    "## Plotting the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e57683b4-7909-4399-8c03-131732593ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "threshold = 0.1\n",
    "\n",
    "for i in range(number_of_points):\n",
    "    confidence_map = output[0, i, :, :]\n",
    "    confidence_map = cv2.resize(confidence_map, (width, heigth))\n",
    "\n",
    "    _, confidence, _, point = cv2.minMaxLoc(confidence_map)\n",
    "\n",
    "    if confidence > threshold:\n",
    "        cv2.circle(copy, (int(point[0]), int(point[1])), 5, pointA_color,\n",
    "                   thickness=thickness_, lineType=cv2.FILLED)\n",
    "        cv2.putText(copy, ' ' + (str(int(point[0]))) + ',' +\n",
    "                    str(int(point[1])), (int(point[0]), int(point[1])),\n",
    "                    font, 0.3, txtpoint_color, 0, lineType=cv2.LINE_AA)\n",
    "\n",
    "        cv2.circle(img, (int(point[0]), int(point[1])), circle_size,\n",
    "                   pointA_color,\n",
    "                   thickness=thickness_, lineType=cv2.FILLED)\n",
    "        cv2.putText(img, ' ' + \"{}\".format(i), (int(point[0]),\n",
    "                                                  int(point[1])),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.3,\n",
    "                    txtpoint_color,\n",
    "                    0, lineType=cv2.LINE_AA)\n",
    "\n",
    "        points.append((int(point[0]), int(point[1])))\n",
    "\n",
    "    else:\n",
    "        points.append((0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc58b191-80ec-4b48-ba82-c5f5e186f7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2a671e8-0dff-46d0-b6a9-139aa94a2ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('hand', img)\n",
    "cv2.waitKey(0)  # Wait for a key press to close the window\n",
    "cv2.destroyAllWindows()  # Close the window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c95a63-5456-4b41-9f43-c4c22d8b4b01",
   "metadata": {},
   "source": [
    "## Drawning the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "395b1092-6cc3-4be8-bf3e-f5d716974ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in pairs:\n",
    "    p1 = pair[0]\n",
    "    p2 = pair[1]\n",
    "\n",
    "    if points[p1] != (0, 0) and points[p2] != (0, 0):\n",
    "        cv2.line(img, points[p1], points[p2], line_color,\n",
    "                 line_size, lineType=cv2.LINE_AA)\n",
    "        cv2.line(img, points[p1], points[p2], line_color, line_size,\n",
    "                 lineType=cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c7309d6-816e-4836-8dd6-c9a78eed7ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)  # Wait for a key press to close the window\n",
    "cv2.destroyAllWindows()  # Close the window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9499d63e-d4a6-44e3-8c71-779d8d63d87b",
   "metadata": {},
   "source": [
    "## Detecting in a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e74af2d1-7a31-44de-8b66-11e24a3e49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_size, line_size, circle_size, thickness_ = 5, 3, 8, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0c8602f1-a825-4939-b348-b5813efd7140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = \"gym.mp4\"\n",
    "capture = cv2.VideoCapture(video)\n",
    "ret, frame = capture.read()\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d29b1ac1-0fe2-4dfd-a45d-8791e141cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = 'hand-detection.mp4'\n",
    "save_video = cv2.VideoWriter(result, cv2.VideoWriter_fourcc(*'mp4v'), 30,\n",
    "                              (frame.shape[1], frame.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b012e6fa-9cb1-4cf3-9fef-0724ab43dc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 720, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a19973c6-f69a-4ef6-b78a-16c0c15cd8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width = frame.shape[1]\n",
    "heigth = frame.shape[0]\n",
    "proportion = width / heigth\n",
    "proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2c36dbb8-5012-4a91-9637-ab47f636ca70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_height = 480\n",
    "new_width = int((proportion*new_height)*8//8)\n",
    "new_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4093b3b7-08bf-4f21-a91c-bb672c62d9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo total = 1.21seg\n",
      "Tempo total = 1.17seg\n",
      "Tempo total = 1.17seg\n",
      "Tempo total = 1.17seg\n",
      "Tempo total = 1.16seg\n",
      "Tempo total = 1.18seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.24seg\n",
      "Tempo total = 1.22seg\n",
      "Tempo total = 1.23seg\n",
      "Tempo total = 1.40seg\n",
      "Tempo total = 1.34seg\n",
      "Tempo total = 1.22seg\n",
      "Tempo total = 1.24seg\n",
      "Tempo total = 1.24seg\n",
      "Tempo total = 1.23seg\n",
      "Tempo total = 1.23seg\n",
      "Tempo total = 1.23seg\n",
      "Tempo total = 1.22seg\n",
      "Tempo total = 1.22seg\n",
      "Tempo total = 1.23seg\n",
      "Tempo total = 1.22seg\n",
      "Tempo total = 1.23seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.30seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.29seg\n",
      "Tempo total = 1.23seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.30seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.24seg\n",
      "Tempo total = 1.23seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.34seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.29seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.29seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.23seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.24seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.24seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.24seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.24seg\n",
      "Tempo total = 1.23seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.24seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.37seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.23seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.29seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.30seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.28seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.26seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.33seg\n",
      "Tempo total = 1.35seg\n",
      "Tempo total = 1.34seg\n",
      "Tempo total = 1.27seg\n",
      "Tempo total = 1.44seg\n",
      "Tempo total = 1.42seg\n",
      "Tempo total = 1.32seg\n",
      "Tempo total = 1.25seg\n",
      "Tempo total = 1.34seg\n",
      "Tempo total = 1.42seg\n",
      "Tempo total = 1.22seg\n",
      "Tempo total = 1.45seg\n",
      "Tempo total = 1.32seg\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.1\n",
    "while (cv2.waitKey(1) < 0):\n",
    "    t = time.time()\n",
    "    connected, frame = capture.read()\n",
    "\n",
    "    if not connected:\n",
    "        break\n",
    "    \n",
    "    frame_copy = np.copy(frame)\n",
    "    size = cv2.resize(frame, (width, heigth))\n",
    "    blur_map = cv2.GaussianBlur(size, (3, 3), 0, 0)\n",
    "    image_background = np.uint8(blur_map > threshold)\n",
    "\n",
    "    blob_entry = cv2.dnn.blobFromImage(frame, 1.0 / 255,\n",
    "                                         (new_width, new_height),\n",
    "                                    (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    model.setInput(blob_entry)\n",
    "    output = model.forward()\n",
    "\n",
    "    points = []\n",
    "\n",
    "    for i in range(number_of_points):\n",
    "        confidence_map = output[0, i, :, :]\n",
    "        confidence_map = cv2.resize(confidence_map, (width, heigth))\n",
    "\n",
    "        _, confidence, _, point = cv2.minMaxLoc(confidence_map)\n",
    "\n",
    "        if confidence > threshold:\n",
    "            cv2.circle(frame_copy, (int(point[0]), int(point[1])),\n",
    "                       circle_size, pointA_color, thickness=thickness_,\n",
    "                       lineType=cv2.FILLED)\n",
    "            cv2.putText(frame_copy, \"{}\".format(i), (int(point[0]), int(point[1])),\n",
    "                        font, .8,\n",
    "                        txtpoint_color, 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "            points.append((int(point[0]), int(point[1])))\n",
    "        else:\n",
    "            points.append((0, 0))\n",
    "\n",
    "    for pair in pairs:\n",
    "        p1 = pair[0]\n",
    "        p2 = pair[1]\n",
    "\n",
    "        if points[p1] != (0, 0) and points[p2] != (0, 0):\n",
    "            cv2.line(frame, points[p1], points[p2], line_color,\n",
    "                     line_size, lineType=cv2.LINE_AA)\n",
    "            cv2.circle(frame, points[p1], circle_size, pointA_color,\n",
    "                       thickness=thickness_, lineType=cv2.FILLED)\n",
    "            cv2.circle(frame, points[p2], circle_size, pointB_color,\n",
    "                       thickness=thickness_, lineType=cv2.FILLED)\n",
    "\n",
    "            cv2.line(image_background, points[p1], points[p2], line_color,\n",
    "                     line_size, lineType=cv2.LINE_AA)\n",
    "            cv2.circle(image_background, points[p1], circle_size, pointA_color,\n",
    "                       thickness=thickness_, lineType=cv2.FILLED)\n",
    "            cv2.circle(image_background, points[p2], circle_size, pointB_color,\n",
    "                       thickness=thickness_, lineType=cv2.FILLED)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "    print(\"Tempo total = {:.2f}seg\".format(time.time() - t))\n",
    "    save_video.write(frame)\n",
    "save_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3bce37-56b7-4f0c-9f6c-d54979b62fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f867c84-d54a-4b18-9276-b9717db03cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
